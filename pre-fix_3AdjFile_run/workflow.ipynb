{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage subset of Russia shp files without clipping to fp fix and with clipping to fp fix in local viz-staging\n",
    "\n",
    "- 3 adjacent ice wedge polygon files from [Wrangle Island](https://www.google.com/maps/place/Wrangel+Island/@71.3497058,179.8238705,9z/data=!4m6!3m5!1s0x50a70636a5f5033f:0xe1dca925085b4bc3!8m2!3d71.2488724!4d-179.9789208!16zL20vMDMyZnRq), off the coasts of Russia & Alaska\n",
    "- bug fix branch of viz-staging, first create staged tiles without fix to visualize in local cesium\n",
    "- then, using same branch, make changes and create tiles again and visualize again and see if it looks different\n",
    "- using conda env `clipToFP_PR`\n",
    "- after running through these steps in chunks in this notebook, it's a great idea to transfer the code to a script and run as a `tmux` session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data import\n",
    "from pathlib import Path\n",
    "\n",
    "# staging\n",
    "import pdgstaging\n",
    "from pdgstaging import TileStager\n",
    "\n",
    "# rasterization\n",
    "import pdgraster\n",
    "from pdgraster import RasterTiler\n",
    "\n",
    "# visual checks\n",
    "import geopandas as gpd\n",
    "\n",
    "# logging\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import logging.handlers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jcohen/iwp_russia_subset_clipToFP_PR/iwp/WV02_20100720235424_1030010006263400_10JUL20235424-M1BS-500226255100_01_P002_u16rf3413_pansh/WV02_20100720235424_1030010006263400_10JUL20235424-M1BS-500226255100_01_P002_u16rf3413_pansh.shp',\n",
       " '/home/jcohen/iwp_russia_subset_clipToFP_PR/iwp/WV02_20100720235425_1030010006263400_10JUL20235425-M1BS-500226255100_01_P003_u16rf3413_pansh/WV02_20100720235425_1030010006263400_10JUL20235425-M1BS-500226255100_01_P003_u16rf3413_pansh.shp',\n",
       " '/home/jcohen/iwp_russia_subset_clipToFP_PR/iwp/WV02_20100720235426_1030010006263400_10JUL20235426-M1BS-500226255100_01_P004_u16rf3413_pansh/WV02_20100720235426_1030010006263400_10JUL20235426-M1BS-500226255100_01_P004_u16rf3413_pansh.shp']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = Path('/home/jcohen/iwp_russia_subset_clipToFP_PR/iwp')\n",
    "filename = '*.shp'\n",
    "# To define each .shp file within each subdir as a string representation with forward slashes, use as_posix()\n",
    "# The ** represents that any subdir string can be present between the base_dir and the filename\n",
    "input = [p.as_posix() for p in base_dir.glob('**/' + filename)]\n",
    "input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the logging configuration\n",
    "\n",
    "This prints logging statements to a file specified by the path in the config. Change the filepath as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = logging.handlers.WatchedFileHandler(\n",
    "    os.environ.get(\"LOGFILE\", \"/home/jcohen/viz-staging/pre-fix_3AdjFile_run/log.log\"))\n",
    "formatter = logging.Formatter(logging.BASIC_FORMAT)\n",
    "handler.setFormatter(formatter)\n",
    "root = logging.getLogger()\n",
    "root.setLevel(os.environ.get(\"LOGLEVEL\", \"INFO\"))\n",
    "root.addHandler(handler)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the files with their footprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull filepaths for footprints in the same way we pulled IWP shp file paths\n",
    "base_dir_fp = Path('/home/jcohen/iwp_russia_subset_clipToFP_PR/footprints')\n",
    "# To define each .shp file within each subdir as a string representation with forward slashes, use as_posix()\n",
    "# The ** represents that any subdir string can be present between the base_dir and the filename\n",
    "fps = [p.as_posix() for p in base_dir_fp.glob('**/' + filename)]\n",
    "fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp = gpd.read_file(input[0])\n",
    "footprint = gpd.read_file(fps[0])\n",
    "ax = shp.plot(color='none', edgecolor='green', linewidths=1.5, figsize=(14,14))\n",
    "footprint.plot(ax=ax, color='none', edgecolor='black', linewidths=0.5, figsize=(14,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp = gpd.read_file(input[1])\n",
    "footprint = gpd.read_file(fps[1])\n",
    "ax = shp.plot(color='none', edgecolor='blue', linewidths=1.5, figsize=(14,14))\n",
    "footprint.plot(ax=ax, color='none', edgecolor='black', linewidths=0.5, figsize=(14,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp = gpd.read_file(input[2])\n",
    "footprint = gpd.read_file(fps[2])\n",
    "ax = shp.plot(color='none', edgecolor='green', linewidths=1.5, figsize=(14,14))\n",
    "footprint.plot(ax=ax, color='none', edgecolor='black', linewidths=0.5, figsize=(14,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 2 non-coastal iwp files together \n",
    "shp1 = gpd.read_file(input[1])\n",
    "shp2 = gpd.read_file(input[2])\n",
    "ax = shp1.plot(color='none', edgecolor='blue', linewidths=1.5, figsize=(14,14), alpha=0.3)\n",
    "shp2.plot(ax=ax, color='none', edgecolor='green', linewidths=0.5, figsize=(14,14), alpha=0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the stager\n",
    "\n",
    "You can input the config directly to `TileStager()`, or save the config as an object earlier in the script, or save the config as a separate `.py` or `.json` script and source it in with:\n",
    "```python\n",
    "# config.py must be a script in same level of folder hierachy as this notebook \n",
    "# that contains config defined as an object like `config = {...}` \n",
    "import config \n",
    "config = config.config\n",
    "pdgstaging.TileStager(config)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stager = TileStager({\n",
    "  \"deduplicate_clip_to_footprint\": True, \n",
    "  \"dir_input\": \"/home/jcohen/iwp_russia_subset_clipToFP_PR/iwp/\", \n",
    "  \"ext_input\": \".shp\",\n",
    "  \"ext_footprints\": \".shp\",\n",
    "  \"dir_footprints\": \"/home/jcohen/iwp_russia_subset_clipToFP_PR/footprints/\", \n",
    "  \"dir_staged\": \"staged/\",\n",
    "  \"dir_geotiff\": \"geotiff/\", \n",
    "  \"dir_web_tiles\": \"web_tiles/\", \n",
    "  \"filename_staging_summary\": \"staging_summary.csv\",\n",
    "  \"filename_rasterization_events\": \"raster_events.csv\",\n",
    "  \"filename_rasters_summary\": \"raster_summary.csv\",\n",
    "  \"filename_config\": \"config\",\n",
    "  \"simplify_tolerance\": 0.1,\n",
    "  \"tms_id\": \"WGS1984Quad\",\n",
    "  \"z_range\": [\n",
    "    0,\n",
    "    15\n",
    "  ],\n",
    "  \"geometricError\": 57,\n",
    "  \"z_coord\": 0,\n",
    "  \"statistics\": [\n",
    "    {\n",
    "      \"name\": \"iwp_coverage\",\n",
    "      \"weight_by\": \"area\",\n",
    "      \"property\": \"area_per_pixel_area\",\n",
    "      \"aggregation_method\": \"sum\",\n",
    "      \"resampling_method\": \"average\",\n",
    "      \"val_range\": [\n",
    "        0,\n",
    "        1\n",
    "      ],\n",
    "      \"palette\": [\n",
    "        \"#66339952\",\n",
    "        \"#ffcc00\"\n",
    "      ],\n",
    "      \"nodata_val\": 0,\n",
    "      \"nodata_color\": \"#ffffff00\"\n",
    "    },\n",
    "  ],\n",
    "  \"deduplicate_at\": [\n",
    "    \"raster\"\n",
    "  ],\n",
    "  \"deduplicate_keep_rules\": [\n",
    "    [\n",
    "      \"Date\",\n",
    "      \"larger\"\n",
    "    ]\n",
    "  ],\n",
    "  \"deduplicate_method\": \"footprints\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stager.stage_all()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rasterization & Web-tiling\n",
    "\n",
    "- Use the `pdgraster.RasterTiler()` function to create the `rasterizer`, then use it to execute the rasterize function: `rasterizer.rasterize_vectors()`.\n",
    "- Alternatively, can run these two steps as one with just `pdgraster.RasterTiler().rasterize_all()`. Just as in staging, you can input the config directly to `RasterTiler()`, or save the config as an object earlier in the script, or save the config as a separate script and source it in. \n",
    "- `rasterize_all()` is a wrapper for `rasterize_vectors()`. It pulls all staged filepaths from the staged dir and rasterizes all z-levels . We do _not_ use `rasterize_all()` when rasterizing in parallel with `parsl` or `ray`. It is exclusively used for small datasets that are not run in parallel. We have to create specific `@parsl` or `@ray.remote` wrapper functions around `stage()` and `rasterize_vectors()` if using those packages for staging, rasterizaiton, etc. For an example, see [here](https://github.com/PermafrostDiscoveryGateway/viz-workflow/blob/8c1997a9d2456bcb79ba1b3ab0f82b3b2b30b141/IN_PROGRESS_VIZ_WORKFLOW.py#L668-L693) for how we rasterize in the ray workflow.\n",
    "- Rasterization when executed with `rasterize_all()` creates `.tif` files in the output `geotiff` dir, _and_ creates the same number of `.png` files in the output `web_tiles` dir.\n",
    "    - When we use `rasterize_vectors()` instead, we _only create the `.tif` files and not the `.png` files_. So that needs to be executed as a separate step with `rasterizer.webtiles_from_geotiffs()` after the `rasterize_vectors() step`, and _in between those steps_ we need to manually \"update the ranges\" in the rasterizer to ensure that the colors within one z-level of `.png` files looks appropriate when visualized in the portal. We will cross that bridge as necessay, just as we do [here](https://github.com/PermafrostDiscoveryGateway/viz-workflow/blob/8c1997a9d2456bcb79ba1b3ab0f82b3b2b30b141/IN_PROGRESS_VIZ_WORKFLOW.py#L592) in the `ray` workflow on Delta.\n",
    "- The number of z-level 15 tiles in the `staged` dir should match the number of z-level 15 tiles in the `geotiff` and `web_tiles` dirs. The total number of files in both the `geotiff` and `web_tiles` dirs is a _lot_ more than the number of files in `staged` because `staged` _only contains the highest zoom level_ with no parent z-levels.\n",
    "- The web tiles are what we actually visualize on the PDG portal and local cesium. We create the rasters for summary stats (the data behind the web tiles, stored in bands of the `.tif` files)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RasterTiler({\n",
    "  \"deduplicate_clip_to_footprint\": True, \n",
    "  \"dir_input\": \"/home/jcohen/iwp_russia_subset_clipToFP_PR/iwp/\", \n",
    "  \"ext_input\": \".shp\",\n",
    "  \"ext_footprints\": \".shp\",\n",
    "  \"dir_footprints\": \"/home/jcohen/iwp_russia_subset_clipToFP_PR/footprints/\", \n",
    "  \"dir_staged\": \"staged/\",\n",
    "  \"dir_geotiff\": \"geotiff/\", \n",
    "  \"dir_web_tiles\": \"web_tiles/\", \n",
    "  \"filename_staging_summary\": \"staging_summary.csv\",\n",
    "  \"filename_rasterization_events\": \"raster_events.csv\",\n",
    "  \"filename_rasters_summary\": \"raster_summary.csv\",\n",
    "  \"filename_config\": \"config\",\n",
    "  \"simplify_tolerance\": 0.1,\n",
    "  \"tms_id\": \"WGS1984Quad\",\n",
    "  \"z_range\": [\n",
    "    0,\n",
    "    15\n",
    "  ],\n",
    "  \"geometricError\": 57,\n",
    "  \"z_coord\": 0,\n",
    "  \"statistics\": [\n",
    "    {\n",
    "      \"name\": \"iwp_coverage\",\n",
    "      \"weight_by\": \"area\",\n",
    "      \"property\": \"area_per_pixel_area\",\n",
    "      \"aggregation_method\": \"sum\",\n",
    "      \"resampling_method\": \"average\",\n",
    "      \"val_range\": [\n",
    "        0,\n",
    "        1\n",
    "      ],\n",
    "      \"palette\": [\n",
    "        \"#66339952\",\n",
    "        \"#ffcc00\"\n",
    "      ],\n",
    "      \"nodata_val\": 0,\n",
    "      \"nodata_color\": \"#ffffff00\"\n",
    "    },\n",
    "  ],\n",
    "  \"deduplicate_at\": [\n",
    "    \"raster\"\n",
    "  ],\n",
    "  \"deduplicate_keep_rules\": [\n",
    "    [\n",
    "      \"Date\",\n",
    "      \"larger\"\n",
    "    ]\n",
    "  ],\n",
    "  \"deduplicate_method\": \"footprints\"\n",
    "}).rasterize_all()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of `geotiff` files produced (for all z-levels): ****\n",
    "\n",
    "Number of `web_tiles` produced (for all z-levels): ****"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clipToFP_PR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage subset of Russia shp files without clipping to fp fix and with clipping to fp fix in local viz-staging\n",
    "\n",
    "- 3 adjacent ice wedge polygon files from [Wrangle Island](https://www.google.com/maps/place/Wrangel+Island/@71.3497058,179.8238705,9z/data=!4m6!3m5!1s0x50a70636a5f5033f:0xe1dca925085b4bc3!8m2!3d71.2488724!4d-179.9789208!16zL20vMDMyZnRq), off the coasts of Russia & Alaska\n",
    "- `bug-17-clippingToFP` branch of `viz-staging`, first create staged tiles without fix to visualize in local cesium\n",
    "- then, using same branch, make changes, create tiles again, and visualize again and see if it looks different\n",
    "- using conda env `clipToFP_PR`\n",
    "- after running through these steps in chunks in this notebook, it's a great idea to transfer the code to a script and run as a `tmux` session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data import\n",
    "from pathlib import Path\n",
    "\n",
    "# staging\n",
    "import pdgstaging\n",
    "from pdgstaging import TileStager\n",
    "\n",
    "# rasterization\n",
    "import pdgraster\n",
    "from pdgraster import RasterTiler\n",
    "\n",
    "# visual checks\n",
    "import geopandas as gpd\n",
    "\n",
    "# logging\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import logging.handlers\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data\n",
    "\n",
    "In order to process 1 or 2 files instead of all 3 adjacent files on Wrangle Island, subset the `input` list of filepaths created below. Estimated times and number of files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path('/home/jcohen/iwp_russia_subset_clipToFP_PR/iwp')\n",
    "filename = '*.shp'\n",
    "# To define each .shp file within each subdir as a string representation with forward slashes, use as_posix()\n",
    "# The ** represents that any subdir string can be present between the base_dir and the filename\n",
    "input = [p.as_posix() for p in base_dir.glob('**/' + filename)]\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull filepaths for footprints in the same way we pulled IWP shp file paths\n",
    "base_dir_fp = Path('/home/jcohen/iwp_russia_subset_clipToFP_PR/footprints')\n",
    "# To define each .shp file within each subdir as a string representation with forward slashes, use as_posix()\n",
    "# The ** represents that any subdir string can be present between the base_dir and the filename\n",
    "fps = [p.as_posix() for p in base_dir_fp.glob('**/' + filename)]\n",
    "fps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the logging configuration\n",
    "\n",
    "This prints logging statements to a file specified by the path in the config. Change the filepath as needed. There will be many logging statements written to that file. It's helpful to ctrl + f for certain logged statements when troubleshooting. For example, if fewer files were staged than expected, you can search for \"error\" or \"failed\". If you are debugging a silent error and suspect that the issue has something to do with the order in which input files are processed, you can search for the input filenames to determine which was staged first. In between runs, it's a good idea to delete the log from the past run, rename it, or archive it elsewhere so the next run's log does not append to the same log file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = logging.handlers.WatchedFileHandler(\n",
    "    os.environ.get(\"LOGFILE\", \"/path/to/output/log.log\"))\n",
    "formatter = logging.Formatter(logging.BASIC_FORMAT)\n",
    "handler.setFormatter(formatter)\n",
    "root = logging.getLogger()\n",
    "root.setLevel(os.environ.get(\"LOGLEVEL\", \"INFO\"))\n",
    "root.addHandler(handler)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the files with their footprints (optional)\n",
    "\n",
    "Each of the following plots takes ~2-5 minutes to generate. Size has been increased in order to see how the IWP polygons spill over the edge of the footprints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first pair\n",
    "shp = gpd.read_file(input[0])\n",
    "footprint = gpd.read_file(fps[0])\n",
    "ax = shp.plot(color='none', edgecolor='green', linewidths=1.5, figsize=(14,14))\n",
    "footprint.plot(ax=ax, color='none', edgecolor='black', linewidths=0.5, figsize=(14,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second pair\n",
    "shp = gpd.read_file(input[1])\n",
    "footprint = gpd.read_file(fps[1])\n",
    "ax = shp.plot(color='none', edgecolor='blue', linewidths=1.5, figsize=(14,14))\n",
    "footprint.plot(ax=ax, color='none', edgecolor='black', linewidths=0.5, figsize=(14,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third pair\n",
    "shp = gpd.read_file(input[2])\n",
    "footprint = gpd.read_file(fps[2])\n",
    "ax = shp.plot(color='none', edgecolor='green', linewidths=1.5, figsize=(14,14))\n",
    "footprint.plot(ax=ax, color='none', edgecolor='black', linewidths=0.5, figsize=(14,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 2 non-coastal adjacent iwp files together, no footprints\n",
    "shp1 = gpd.read_file(input[1])\n",
    "shp2 = gpd.read_file(input[2])\n",
    "ax = shp1.plot(color='none', edgecolor='blue', linewidths=1.5, figsize=(14,14), alpha=0.3)\n",
    "shp2.plot(ax=ax, color='none', edgecolor='green', linewidths=0.5, figsize=(14,14), alpha=0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the stager\n",
    "\n",
    "You can input the config directly to `TileStager()`, or save the config as an object earlier in the script, or save the config as a separate `.py` or `.json` script and source it in with:\n",
    "```python\n",
    "# config.py must be a script in same level of folder hierachy as this notebook \n",
    "# that contains config defined as an object like `config = {...}` \n",
    "import config \n",
    "config = config.config\n",
    "pdgstaging.TileStager(config)\n",
    "```\n",
    "\n",
    "- Many of the settings in the config specified below are defaults. You can find default values for the config [here](https://github.com/PermafrostDiscoveryGateway/viz-staging/blob/4f31e951600d54c128f76b48a47ec390261fb548/pdgstaging/ConfigManager.py#L351-L422).\n",
    "- You'll notice that the statistics (calculated during rasterization, each becomes a band) are tailored towards ice wedge polygons. You can remove an entire statistic, or change them as desired. The \"name\" of each statistic can be anything.\n",
    "- I would not recommend changing the number of z-levels. \n",
    "- Color palette can be changed, but must be at least 2 values.\n",
    "- Input data types for the staging step should be vectors, like `.shp` or `.gpkg`. We specify `.shp` below because the IWP input data are shapefiles. \n",
    "\n",
    "For more information about the configuration, there is extensive documentation in [PermafrostDiscoveryGateway/viz-staging/pdgstaging/ConfigManager.py](https://github.com/PermafrostDiscoveryGateway/viz-staging/blob/main/pdgstaging/ConfigManager.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stager = TileStager({\n",
    "  \"deduplicate_clip_to_footprint\": True, \n",
    "  \"dir_input\": \"/home/jcohen/iwp_russia_subset_clipToFP_PR/iwp/\", \n",
    "  \"ext_input\": \".shp\",\n",
    "  \"ext_footprints\": \".shp\",\n",
    "  \"dir_footprints\": \"/home/jcohen/iwp_russia_subset_clipToFP_PR/footprints/\", \n",
    "  \"dir_staged\": \"staged/\",\n",
    "  \"dir_geotiff\": \"geotiff/\", \n",
    "  \"dir_web_tiles\": \"web_tiles/\", \n",
    "  \"filename_staging_summary\": \"staging_summary.csv\",\n",
    "  \"filename_rasterization_events\": \"raster_events.csv\",\n",
    "  \"filename_rasters_summary\": \"raster_summary.csv\",\n",
    "  \"filename_config\": \"config\",\n",
    "  \"simplify_tolerance\": 0.1,\n",
    "  \"tms_id\": \"WGS1984Quad\",\n",
    "  \"z_range\": [\n",
    "    0,\n",
    "    15\n",
    "  ],\n",
    "  \"geometricError\": 57,\n",
    "  \"z_coord\": 0,\n",
    "  \"statistics\": [\n",
    "    {\n",
    "      \"name\": \"iwp_coverage\",\n",
    "      \"weight_by\": \"area\",\n",
    "      \"property\": \"area_per_pixel_area\",\n",
    "      \"aggregation_method\": \"sum\",\n",
    "      \"resampling_method\": \"average\",\n",
    "      \"val_range\": [\n",
    "        0,\n",
    "        1\n",
    "      ],\n",
    "      \"palette\": [\n",
    "        \"#66339952\",\n",
    "        \"#ffcc00\"\n",
    "      ],\n",
    "      \"nodata_val\": 0,\n",
    "      \"nodata_color\": \"#ffffff00\"\n",
    "    },\n",
    "  ],\n",
    "  \"deduplicate_at\": [\n",
    "    \"raster\"\n",
    "  ],\n",
    "  \"deduplicate_keep_rules\": [\n",
    "    [\n",
    "      \"Date\",\n",
    "      \"larger\"\n",
    "    ]\n",
    "  ],\n",
    "  \"deduplicate_method\": \"footprints\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stager.stage_all()\n",
    "# took about 26 minutes for all 3 files to stage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rasterization & web-tiling\n",
    "\n",
    "- Use the `pdgraster.RasterTiler()` function to create the `rasterizer`, then use it to execute the rasterize function: `rasterizer.rasterize_vectors()`.\n",
    "- Alternatively, can run these two steps as one with just `pdgraster.RasterTiler().rasterize_all()`. Just as in staging, you can input the config directly to `RasterTiler()`, or save the config as an object earlier in the script, or save the config as a separate script and source it in. \n",
    "- `rasterize_all()` is a wrapper for `rasterize_vectors()`. It pulls all staged filepaths from the staged dir and rasterizes all z-levels . We do _not_ use `rasterize_all()` when rasterizing in parallel with `parsl` or `ray`. It is exclusively used for small datasets that are not run in parallel. We have to create specific `@parsl` or `@ray.remote` wrapper functions around `stage()` and `rasterize_vectors()` if using those packages for staging, rasterizaiton, etc. For an example, see [here](https://github.com/PermafrostDiscoveryGateway/viz-workflow/blob/8c1997a9d2456bcb79ba1b3ab0f82b3b2b30b141/IN_PROGRESS_VIZ_WORKFLOW.py#L668-L693) for how we rasterize in the ray workflow.\n",
    "- Rasterization when executed with `rasterize_all()` creates `.tif` files in the output `geotiff` dir, _and_ creates the same number of `.png` files in the output `web_tiles` dir.\n",
    "    - When we use `rasterize_vectors()` instead, we _only create the `.tif` files and not the `.png` files_. So that needs to be executed as a separate step with `rasterizer.webtiles_from_geotiffs()` after the `rasterize_vectors() step`, and _in between those steps_ we need to manually \"update the ranges\" in the rasterizer to ensure that the colors within one z-level of `.png` files looks appropriate when visualized in the portal. We will cross that bridge as necessay, just as we do [here](https://github.com/PermafrostDiscoveryGateway/viz-workflow/blob/8c1997a9d2456bcb79ba1b3ab0f82b3b2b30b141/IN_PROGRESS_VIZ_WORKFLOW.py#L592) in the `ray` workflow on Delta.\n",
    "- The number of z-level 15 tiles in the `staged` dir should match the number of z-level 15 tiles in the `geotiff` and `web_tiles` dirs. The total number of files in both the `geotiff` and `web_tiles` dirs is a _lot_ more than the number of files in `staged` because `staged` _only contains the highest zoom level_ with no parent z-levels.\n",
    "- The web tiles are what we actually visualize on the PDG portal and local cesium. We create the rasters for summary stats (the data behind the web tiles, stored in bands of the `.tif` files)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RasterTiler({\n",
    "  \"deduplicate_clip_to_footprint\": True, \n",
    "  \"dir_input\": \"/home/jcohen/iwp_russia_subset_clipToFP_PR/iwp/\", \n",
    "  \"ext_input\": \".shp\",\n",
    "  \"ext_footprints\": \".shp\",\n",
    "  \"dir_footprints\": \"/home/jcohen/iwp_russia_subset_clipToFP_PR/footprints/\", \n",
    "  \"dir_staged\": \"staged/\",\n",
    "  \"dir_geotiff\": \"geotiff/\", \n",
    "  \"dir_web_tiles\": \"web_tiles/\", \n",
    "  \"filename_staging_summary\": \"staging_summary.csv\",\n",
    "  \"filename_rasterization_events\": \"raster_events.csv\",\n",
    "  \"filename_rasters_summary\": \"raster_summary.csv\",\n",
    "  \"filename_config\": \"config\",\n",
    "  \"simplify_tolerance\": 0.1,\n",
    "  \"tms_id\": \"WGS1984Quad\",\n",
    "  \"z_range\": [\n",
    "    0,\n",
    "    15\n",
    "  ],\n",
    "  \"geometricError\": 57,\n",
    "  \"z_coord\": 0,\n",
    "  \"statistics\": [\n",
    "    {\n",
    "      \"name\": \"iwp_coverage\",\n",
    "      \"weight_by\": \"area\",\n",
    "      \"property\": \"area_per_pixel_area\",\n",
    "      \"aggregation_method\": \"sum\",\n",
    "      \"resampling_method\": \"average\",\n",
    "      \"val_range\": [\n",
    "        0,\n",
    "        1\n",
    "      ],\n",
    "      \"palette\": [\n",
    "        \"#66339952\",\n",
    "        \"#ffcc00\"\n",
    "      ],\n",
    "      \"nodata_val\": 0,\n",
    "      \"nodata_color\": \"#ffffff00\"\n",
    "    },\n",
    "  ],\n",
    "  \"deduplicate_at\": [\n",
    "    \"raster\"\n",
    "  ],\n",
    "  \"deduplicate_keep_rules\": [\n",
    "    [\n",
    "      \"Date\",\n",
    "      \"larger\"\n",
    "    ]\n",
    "  ],\n",
    "  \"deduplicate_method\": \"footprints\"\n",
    "}).rasterize_all()\n",
    "\n",
    "# took about 61 min for all staged files to rasterize and web tile"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of `geotiff` files produced (for all z-levels): **4376**\n",
    "\n",
    "Number of `web_tiles` produced (for all z-levels): **4376**\n",
    "\n",
    "-----------\n",
    "\n",
    "You can use `rasterio` to plot the rasters if you want to get an idea what the statistics look like. Change the number to choose which band (statistic) to visualize. Example:\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "\n",
    "file1 = rasterio.open('/path/to/raster.tif')\n",
    "\n",
    "plt.imshow(file1.read(1), cmap='pink')\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the web tiles\n",
    "\n",
    "Ypu can simply open the `.png` files to view them one at a time, but it's much better to view them on a Cesium basemap! For steps for how to visualize the web tiles with local Cesium, see [documentation here in pdg-info](https://github.com/robyngit/pdg-info/blob/main/05_displaying-the-tiles.md#option-1-run-cesium-locally)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clipToFP_PR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
